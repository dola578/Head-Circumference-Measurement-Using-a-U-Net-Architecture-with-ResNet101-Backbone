{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1801f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801e54c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall typing_extensions\n",
    "# !pip install typing_extensions==4.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c8f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install typing_extensions>=4.3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a1b91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30e90da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting typing_extensions==4.12.2\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing_extensions\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.13.0\n",
      "    Uninstalling typing_extensions-4.13.0:\n",
      "      Successfully uninstalled typing_extensions-4.13.0\n",
      "Successfully installed typing_extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install typing_extensions==4.12.2 --upgrade\n",
    "# pip install typing_extensions==4.7.1 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8758f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypeIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee1b1c",
   "metadata": {},
   "source": [
    "**Preprocessing - flipping, resizing, rotation, gamma correction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe0d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = [os.path.join(image_dir, x) for x in os.listdir(image_dir) if x.endswith('.png')]\n",
    "        self.masks = [os.path.join(mask_dir, x) for x in os.listdir(mask_dir) if 'Annotation' in x]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        mask_path = self.masks[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        return image, mask\n",
    "\n",
    "# Define transformations including geometric and intensity-based augmentations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((572, 572)),  # Resize images to match U-Net expected input\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flipping\n",
    "    transforms.RandomVerticalFlip(),  # Random vertical flipping\n",
    "    transforms.RandomRotation(20),  # Random rotations between -20 to 20 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Random brightness and contrast adjustments\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.pow(0.5))  # Gamma correction with gamma=0.5\n",
    "])\n",
    "\n",
    "# Initialize dataset\n",
    "full_dataset = CustomDataset('denoised_training_set', 'masked_annotations', transform=transform)\n",
    "\n",
    "# Splitting the dataset into train and validation sets\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "validation_size = len(full_dataset) - train_size\n",
    "train_dataset, validation_dataset = random_split(full_dataset, [train_size, validation_size])\n",
    "\n",
    "# Create separate dataloaders for train and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12258a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, train_loader and validation_loader can be used in training and validation phases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b61e302",
   "metadata": {},
   "source": [
    "**Unet with resnet101 as backbone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a664895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "class ResConv(nn.Module):\n",
    "    \"\"\" Convolution block for U-Net with repeated convolutions and ReLU activations. \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(ResConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    \"\"\" Upsampling block for U-Net, using bilinear interpolation and convolution. \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(UpConv, self).__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = ResConv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, from_down, from_up):\n",
    "        from_up = self.up(from_up)\n",
    "        diffY = from_down.size()[2] - from_up.size()[2]\n",
    "        diffX = from_down.size()[3] - from_up.size()[3]\n",
    "        from_up = F.pad(from_up, [diffX // 2, diffX - diffX // 2,\n",
    "                                  diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([from_down, from_up], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNetResNet101(nn.Module):\n",
    "    def __init__(self, n_classes=1):\n",
    "        super(UNetResNet101, self).__init__()\n",
    "        base_model = models.resnet101(pretrained=True)\n",
    "        self.base_layers = list(base_model.children())\n",
    "        \n",
    "        # Extract layers from ResNet101\n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3])  # conv1, bn1, relu\n",
    "        self.maxpool = self.base_layers[3]\n",
    "        self.layer1 = self.base_layers[4]  # Output: 256 channels\n",
    "        self.layer2 = self.base_layers[5]  # Output: 512 channels\n",
    "        self.layer3 = self.base_layers[6]  # Output: 1024 channels\n",
    "        self.layer4 = self.base_layers[7]  # Output: 2048 channels\n",
    "\n",
    "        # Decoder (make sure the channel numbers match the skip connection outputs)\n",
    "        self.up4 = UpConv(2048 + 1024, 1024)  # Concatenating x3 (1024) and x4 (2048) -> 3072 channels\n",
    "        self.up3 = UpConv(1024 + 512, 512)    # Concatenating x2 (512) and previous output (1024) -> 1536 channels\n",
    "        self.up2 = UpConv(512 + 256, 256)     # Concatenating x1 (256) and previous output (512) -> 768 channels\n",
    "        self.up1 = UpConv(256 + 64, 64)       # Concatenating x0 (64) and previous output (256) -> 320 channels\n",
    "\n",
    "        # Final upsampling and output convolution to match input size\n",
    "        self.final_up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.final_conv = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder: get intermediate features for skip connections\n",
    "        x0 = self.layer0(x)       # Early features, e.g., 64 channels\n",
    "        x1 = self.maxpool(x0)\n",
    "        x1 = self.layer1(x1)      # 256 channels\n",
    "        x2 = self.layer2(x1)      # 512 channels\n",
    "        x3 = self.layer3(x2)      # 1024 channels\n",
    "        x4 = self.layer4(x3)      # 2048 channels\n",
    "\n",
    "        # Decoder: use skip connections from intermediate features\n",
    "        x = self.up4(x3, x4)      # Upsample: x3 (from_down) + x4 (from_up)\n",
    "        x = self.up3(x2, x)       # Upsample: x2 + output of previous block\n",
    "        x = self.up2(x1, x)       # Upsample: x1 + output of previous block\n",
    "        x = self.up1(x0, x)       # Upsample: x0 + output of previous block\n",
    "\n",
    "        x = self.final_up(x)      # Final upsampling to the original size\n",
    "        x = self.final_conv(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af22e554",
   "metadata": {},
   "source": [
    "**Dice loss + Binary cross-entropy loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f608ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        # Flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice_loss = 1 - (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  \n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "        \n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb63fea",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6214ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a14816a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.8501, Train F1: 0.7885, Validation Loss: 0.8071, Validation F1: 0.7872\n",
      "Epoch 2/50, Train Loss: 0.7883, Train F1: 0.7998, Validation Loss: 0.7780, Validation F1: 0.7966\n",
      "Epoch 3/50, Train Loss: 0.7679, Train F1: 0.7968, Validation Loss: 0.7792, Validation F1: 0.7940\n",
      "Epoch 4/50, Train Loss: 0.7699, Train F1: 0.8015, Validation Loss: 0.7594, Validation F1: 0.8000\n",
      "Epoch 5/50, Train Loss: 0.7587, Train F1: 0.8008, Validation Loss: 0.7665, Validation F1: 0.7956\n",
      "Epoch 6/50, Train Loss: 0.7553, Train F1: 0.8023, Validation Loss: 0.7756, Validation F1: 0.7999\n",
      "Epoch 7/50, Train Loss: 0.7583, Train F1: 0.8029, Validation Loss: 0.7651, Validation F1: 0.7999\n",
      "Epoch 8/50, Train Loss: 0.7492, Train F1: 0.8036, Validation Loss: 0.7808, Validation F1: 0.8008\n",
      "Epoch 9/50, Train Loss: 0.7628, Train F1: 0.8045, Validation Loss: 0.7625, Validation F1: 0.8023\n",
      "Epoch 10/50, Train Loss: 0.7531, Train F1: 0.8028, Validation Loss: 0.7544, Validation F1: 0.7996\n",
      "Epoch 11/50, Train Loss: 0.7620, Train F1: 0.8040, Validation Loss: 0.7775, Validation F1: 0.8011\n",
      "Epoch 12/50, Train Loss: 0.7587, Train F1: 0.8035, Validation Loss: 0.7559, Validation F1: 0.7996\n",
      "Epoch 13/50, Train Loss: 0.7543, Train F1: 0.8036, Validation Loss: 0.7668, Validation F1: 0.7999\n",
      "Epoch 14/50, Train Loss: 0.7527, Train F1: 0.8041, Validation Loss: 0.7682, Validation F1: 0.8019\n",
      "Epoch 15/50, Train Loss: 0.7362, Train F1: 0.8043, Validation Loss: 0.7545, Validation F1: 0.8010\n",
      "Epoch 16/50, Train Loss: 0.7520, Train F1: 0.8035, Validation Loss: 0.7553, Validation F1: 0.8017\n",
      "Epoch 17/50, Train Loss: 0.7572, Train F1: 0.8034, Validation Loss: 0.7569, Validation F1: 0.8011\n",
      "Epoch 18/50, Train Loss: 0.7420, Train F1: 0.8026, Validation Loss: 0.7799, Validation F1: 0.7980\n",
      "Epoch 19/50, Train Loss: 0.7694, Train F1: 0.8052, Validation Loss: 0.7570, Validation F1: 0.8017\n",
      "Epoch 20/50, Train Loss: 0.7515, Train F1: 0.8045, Validation Loss: 0.7526, Validation F1: 0.8014\n",
      "Epoch 21/50, Train Loss: 0.7553, Train F1: 0.8041, Validation Loss: 0.7606, Validation F1: 0.8009\n",
      "Epoch 22/50, Train Loss: 0.7479, Train F1: 0.8048, Validation Loss: 0.7739, Validation F1: 0.8008\n",
      "Epoch 23/50, Train Loss: 0.7485, Train F1: 0.8048, Validation Loss: 0.7492, Validation F1: 0.8026\n",
      "Epoch 24/50, Train Loss: 0.7528, Train F1: 0.8034, Validation Loss: 0.7610, Validation F1: 0.8025\n",
      "Epoch 25/50, Train Loss: 0.7563, Train F1: 0.8045, Validation Loss: 0.7850, Validation F1: 0.8012\n",
      "Epoch 26/50, Train Loss: 0.7493, Train F1: 0.8050, Validation Loss: 0.7547, Validation F1: 0.8023\n",
      "Epoch 27/50, Train Loss: 0.7517, Train F1: 0.8054, Validation Loss: 0.7895, Validation F1: 0.8016\n",
      "Epoch 28/50, Train Loss: 0.7547, Train F1: 0.8025, Validation Loss: 0.7510, Validation F1: 0.8004\n",
      "Epoch 29/50, Train Loss: 0.7470, Train F1: 0.8054, Validation Loss: 0.7636, Validation F1: 0.8021\n",
      "Epoch 30/50, Train Loss: 0.7488, Train F1: 0.8046, Validation Loss: 0.7644, Validation F1: 0.8006\n",
      "Epoch 31/50, Train Loss: 0.7461, Train F1: 0.8039, Validation Loss: 0.7649, Validation F1: 0.8014\n",
      "Epoch 32/50, Train Loss: 0.7606, Train F1: 0.8047, Validation Loss: 0.7484, Validation F1: 0.8016\n",
      "Epoch 33/50, Train Loss: 0.7416, Train F1: 0.8045, Validation Loss: 0.7640, Validation F1: 0.7998\n",
      "Epoch 34/50, Train Loss: 0.7474, Train F1: 0.8037, Validation Loss: 0.7468, Validation F1: 0.7999\n",
      "Epoch 35/50, Train Loss: 0.7466, Train F1: 0.8021, Validation Loss: 0.7842, Validation F1: 0.7971\n",
      "Epoch 36/50, Train Loss: 0.7523, Train F1: 0.8046, Validation Loss: 0.7499, Validation F1: 0.8025\n",
      "Epoch 37/50, Train Loss: 0.7546, Train F1: 0.8062, Validation Loss: 0.7588, Validation F1: 0.8017\n",
      "Epoch 38/50, Train Loss: 0.7468, Train F1: 0.8058, Validation Loss: 0.7818, Validation F1: 0.8022\n",
      "Epoch 39/50, Train Loss: 0.7522, Train F1: 0.8064, Validation Loss: 0.7487, Validation F1: 0.8004\n",
      "Epoch 40/50, Train Loss: 0.7474, Train F1: 0.8066, Validation Loss: 0.7653, Validation F1: 0.8000\n",
      "Epoch 41/50, Train Loss: 0.7535, Train F1: 0.8069, Validation Loss: 0.7700, Validation F1: 0.8000\n",
      "Epoch 42/50, Train Loss: 0.7467, Train F1: 0.8067, Validation Loss: 0.7568, Validation F1: 0.7993\n",
      "Epoch 43/50, Train Loss: 0.7477, Train F1: 0.8054, Validation Loss: 0.7678, Validation F1: 0.8018\n",
      "Epoch 44/50, Train Loss: 0.7451, Train F1: 0.8059, Validation Loss: 0.7523, Validation F1: 0.8009\n",
      "Epoch 45/50, Train Loss: 0.7389, Train F1: 0.8073, Validation Loss: 0.7593, Validation F1: 0.8017\n",
      "Epoch 46/50, Train Loss: 0.7362, Train F1: 0.8099, Validation Loss: 0.7616, Validation F1: 0.7985\n",
      "Epoch 47/50, Train Loss: 0.7362, Train F1: 0.8121, Validation Loss: 0.7562, Validation F1: 0.7964\n",
      "Epoch 48/50, Train Loss: 0.7236, Train F1: 0.8139, Validation Loss: 0.7718, Validation F1: 0.7960\n",
      "Epoch 49/50, Train Loss: 0.7386, Train F1: 0.8145, Validation Loss: 0.7815, Validation F1: 0.7922\n",
      "Epoch 50/50, Train Loss: 0.7222, Train F1: 0.8167, Validation Loss: 0.7715, Validation F1: 0.7928\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Assuming UNetResNet101 and DiceBCELoss are already imported\n",
    "model = UNetResNet101().to(device)  # Ensure your model is the one with ResNet-101\n",
    "loss_function = DiceBCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "num_epochs = 50  # Set the number of epochs you want to train for\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Compute training metrics in evaluation mode\n",
    "    model.eval()\n",
    "    train_loss = 0.0\n",
    "    all_train_preds = []\n",
    "    all_train_targets = []\n",
    "    with torch.no_grad():\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, masks)\n",
    "            train_loss += loss.item()\n",
    "            # Threshold outputs and targets at 0.5 to obtain binary predictions\n",
    "            preds = (outputs > 0.5).float()\n",
    "            binary_masks = (masks > 0.5).float()\n",
    "            all_train_preds.append(preds.cpu().numpy().flatten())\n",
    "            all_train_targets.append(binary_masks.cpu().numpy().flatten())\n",
    "    all_train_preds = np.concatenate(all_train_preds)\n",
    "    all_train_targets = np.concatenate(all_train_targets)\n",
    "    train_f1 = f1_score(all_train_targets, all_train_preds)\n",
    "\n",
    "    # Compute validation metrics\n",
    "    val_loss = 0.0\n",
    "    all_val_preds = []\n",
    "    all_val_targets = []\n",
    "    with torch.no_grad():\n",
    "        for images, masks in validation_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "            preds = (outputs > 0.5).float()\n",
    "            binary_masks = (masks > 0.5).float()\n",
    "            all_val_preds.append(preds.cpu().numpy().flatten())\n",
    "            all_val_targets.append(binary_masks.cpu().numpy().flatten())\n",
    "    all_val_preds = np.concatenate(all_val_preds)\n",
    "    all_val_targets = np.concatenate(all_val_targets)\n",
    "    val_f1 = f1_score(all_val_targets, all_val_preds)\n",
    "\n",
    "    # Print epoch summary with both training and validation metrics\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "          f'Train Loss: {running_loss/len(train_loader):.4f}, Train F1: {train_f1:.4f}, '\n",
    "          f'Validation Loss: {val_loss/len(validation_loader):.4f}, Validation F1: {val_f1:.4f}')\n",
    "    \n",
    "    # Adjust learning rate based on the validation loss\n",
    "    scheduler.step(val_loss/len(validation_loader))\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'unet_resnet101_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c257ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = UNetResNet101(n_classes=1).to(device)\n",
    "# dummy_input = torch.rand(1, 3, 224, 224).to(device)  # Adjust input size as necessary\n",
    "# output = model(dummy_input)\n",
    "# print(\"Output size:\", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214323f5",
   "metadata": {},
   "source": [
    "**Running Model on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3acc027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved segmentation for 000_HC.png at output_segmentations/seg_000_HC.png\n",
      "Saved segmentation for 001_HC.png at output_segmentations/seg_001_HC.png\n",
      "Saved segmentation for 002_HC.png at output_segmentations/seg_002_HC.png\n",
      "Saved segmentation for 003_HC.png at output_segmentations/seg_003_HC.png\n",
      "Saved segmentation for 004_HC.png at output_segmentations/seg_004_HC.png\n",
      "Saved segmentation for 005_HC.png at output_segmentations/seg_005_HC.png\n",
      "Saved segmentation for 006_HC.png at output_segmentations/seg_006_HC.png\n",
      "Saved segmentation for 007_HC.png at output_segmentations/seg_007_HC.png\n",
      "Saved segmentation for 008_HC.png at output_segmentations/seg_008_HC.png\n",
      "Saved segmentation for 009_HC.png at output_segmentations/seg_009_HC.png\n",
      "Saved segmentation for 010_HC.png at output_segmentations/seg_010_HC.png\n",
      "Saved segmentation for 011_HC.png at output_segmentations/seg_011_HC.png\n",
      "Saved segmentation for 012_HC.png at output_segmentations/seg_012_HC.png\n",
      "Saved segmentation for 013_HC.png at output_segmentations/seg_013_HC.png\n",
      "Saved segmentation for 014_HC.png at output_segmentations/seg_014_HC.png\n",
      "Saved segmentation for 015_HC.png at output_segmentations/seg_015_HC.png\n",
      "Saved segmentation for 016_HC.png at output_segmentations/seg_016_HC.png\n",
      "Saved segmentation for 017_HC.png at output_segmentations/seg_017_HC.png\n",
      "Saved segmentation for 018_HC.png at output_segmentations/seg_018_HC.png\n",
      "Saved segmentation for 019_HC.png at output_segmentations/seg_019_HC.png\n",
      "Saved segmentation for 020_HC.png at output_segmentations/seg_020_HC.png\n",
      "Saved segmentation for 021_HC.png at output_segmentations/seg_021_HC.png\n",
      "Saved segmentation for 022_HC.png at output_segmentations/seg_022_HC.png\n",
      "Saved segmentation for 023_HC.png at output_segmentations/seg_023_HC.png\n",
      "Saved segmentation for 024_HC.png at output_segmentations/seg_024_HC.png\n",
      "Saved segmentation for 025_HC.png at output_segmentations/seg_025_HC.png\n",
      "Saved segmentation for 026_HC.png at output_segmentations/seg_026_HC.png\n",
      "Saved segmentation for 027_HC.png at output_segmentations/seg_027_HC.png\n",
      "Saved segmentation for 028_HC.png at output_segmentations/seg_028_HC.png\n",
      "Saved segmentation for 029_HC.png at output_segmentations/seg_029_HC.png\n",
      "Saved segmentation for 030_HC.png at output_segmentations/seg_030_HC.png\n",
      "Saved segmentation for 031_HC.png at output_segmentations/seg_031_HC.png\n",
      "Saved segmentation for 032_HC.png at output_segmentations/seg_032_HC.png\n",
      "Saved segmentation for 033_HC.png at output_segmentations/seg_033_HC.png\n",
      "Saved segmentation for 034_HC.png at output_segmentations/seg_034_HC.png\n",
      "Saved segmentation for 035_HC.png at output_segmentations/seg_035_HC.png\n",
      "Saved segmentation for 036_HC.png at output_segmentations/seg_036_HC.png\n",
      "Saved segmentation for 037_HC.png at output_segmentations/seg_037_HC.png\n",
      "Saved segmentation for 038_HC.png at output_segmentations/seg_038_HC.png\n",
      "Saved segmentation for 039_HC.png at output_segmentations/seg_039_HC.png\n",
      "Saved segmentation for 040_HC.png at output_segmentations/seg_040_HC.png\n",
      "Saved segmentation for 041_HC.png at output_segmentations/seg_041_HC.png\n",
      "Saved segmentation for 042_HC.png at output_segmentations/seg_042_HC.png\n",
      "Saved segmentation for 043_HC.png at output_segmentations/seg_043_HC.png\n",
      "Saved segmentation for 044_HC.png at output_segmentations/seg_044_HC.png\n",
      "Saved segmentation for 045_HC.png at output_segmentations/seg_045_HC.png\n",
      "Saved segmentation for 046_HC.png at output_segmentations/seg_046_HC.png\n",
      "Saved segmentation for 047_HC.png at output_segmentations/seg_047_HC.png\n",
      "Saved segmentation for 048_HC.png at output_segmentations/seg_048_HC.png\n",
      "Saved segmentation for 049_HC.png at output_segmentations/seg_049_HC.png\n",
      "Saved segmentation for 050_HC.png at output_segmentations/seg_050_HC.png\n",
      "Saved segmentation for 051_HC.png at output_segmentations/seg_051_HC.png\n",
      "Saved segmentation for 052_HC.png at output_segmentations/seg_052_HC.png\n",
      "Saved segmentation for 053_HC.png at output_segmentations/seg_053_HC.png\n",
      "Saved segmentation for 054_HC.png at output_segmentations/seg_054_HC.png\n",
      "Saved segmentation for 055_HC.png at output_segmentations/seg_055_HC.png\n",
      "Saved segmentation for 056_HC.png at output_segmentations/seg_056_HC.png\n",
      "Saved segmentation for 057_HC.png at output_segmentations/seg_057_HC.png\n",
      "Saved segmentation for 058_HC.png at output_segmentations/seg_058_HC.png\n",
      "Saved segmentation for 059_HC.png at output_segmentations/seg_059_HC.png\n",
      "Saved segmentation for 060_HC.png at output_segmentations/seg_060_HC.png\n",
      "Saved segmentation for 061_HC.png at output_segmentations/seg_061_HC.png\n",
      "Saved segmentation for 062_HC.png at output_segmentations/seg_062_HC.png\n",
      "Saved segmentation for 063_HC.png at output_segmentations/seg_063_HC.png\n",
      "Saved segmentation for 064_HC.png at output_segmentations/seg_064_HC.png\n",
      "Saved segmentation for 065_HC.png at output_segmentations/seg_065_HC.png\n",
      "Saved segmentation for 066_HC.png at output_segmentations/seg_066_HC.png\n",
      "Saved segmentation for 067_HC.png at output_segmentations/seg_067_HC.png\n",
      "Saved segmentation for 068_HC.png at output_segmentations/seg_068_HC.png\n",
      "Saved segmentation for 069_HC.png at output_segmentations/seg_069_HC.png\n",
      "Saved segmentation for 070_HC.png at output_segmentations/seg_070_HC.png\n",
      "Saved segmentation for 071_HC.png at output_segmentations/seg_071_HC.png\n",
      "Saved segmentation for 072_HC.png at output_segmentations/seg_072_HC.png\n",
      "Saved segmentation for 073_HC.png at output_segmentations/seg_073_HC.png\n",
      "Saved segmentation for 074_HC.png at output_segmentations/seg_074_HC.png\n",
      "Saved segmentation for 075_HC.png at output_segmentations/seg_075_HC.png\n",
      "Saved segmentation for 076_HC.png at output_segmentations/seg_076_HC.png\n",
      "Saved segmentation for 077_HC.png at output_segmentations/seg_077_HC.png\n",
      "Saved segmentation for 078_HC.png at output_segmentations/seg_078_HC.png\n",
      "Saved segmentation for 079_HC.png at output_segmentations/seg_079_HC.png\n",
      "Saved segmentation for 080_HC.png at output_segmentations/seg_080_HC.png\n",
      "Saved segmentation for 081_HC.png at output_segmentations/seg_081_HC.png\n",
      "Saved segmentation for 082_HC.png at output_segmentations/seg_082_HC.png\n",
      "Saved segmentation for 083_HC.png at output_segmentations/seg_083_HC.png\n",
      "Saved segmentation for 084_HC.png at output_segmentations/seg_084_HC.png\n",
      "Saved segmentation for 085_HC.png at output_segmentations/seg_085_HC.png\n",
      "Saved segmentation for 086_HC.png at output_segmentations/seg_086_HC.png\n",
      "Saved segmentation for 087_HC.png at output_segmentations/seg_087_HC.png\n",
      "Saved segmentation for 088_HC.png at output_segmentations/seg_088_HC.png\n",
      "Saved segmentation for 089_HC.png at output_segmentations/seg_089_HC.png\n",
      "Saved segmentation for 090_HC.png at output_segmentations/seg_090_HC.png\n",
      "Saved segmentation for 091_HC.png at output_segmentations/seg_091_HC.png\n",
      "Saved segmentation for 092_HC.png at output_segmentations/seg_092_HC.png\n",
      "Saved segmentation for 093_HC.png at output_segmentations/seg_093_HC.png\n",
      "Saved segmentation for 094_HC.png at output_segmentations/seg_094_HC.png\n",
      "Saved segmentation for 095_HC.png at output_segmentations/seg_095_HC.png\n",
      "Saved segmentation for 096_HC.png at output_segmentations/seg_096_HC.png\n",
      "Saved segmentation for 097_HC.png at output_segmentations/seg_097_HC.png\n",
      "Saved segmentation for 098_HC.png at output_segmentations/seg_098_HC.png\n",
      "Saved segmentation for 099_HC.png at output_segmentations/seg_099_HC.png\n",
      "Saved segmentation for 100_HC.png at output_segmentations/seg_100_HC.png\n",
      "Saved segmentation for 101_HC.png at output_segmentations/seg_101_HC.png\n",
      "Saved segmentation for 102_HC.png at output_segmentations/seg_102_HC.png\n",
      "Saved segmentation for 103_HC.png at output_segmentations/seg_103_HC.png\n",
      "Saved segmentation for 104_HC.png at output_segmentations/seg_104_HC.png\n",
      "Saved segmentation for 105_HC.png at output_segmentations/seg_105_HC.png\n",
      "Saved segmentation for 106_HC.png at output_segmentations/seg_106_HC.png\n",
      "Saved segmentation for 107_HC.png at output_segmentations/seg_107_HC.png\n",
      "Saved segmentation for 108_HC.png at output_segmentations/seg_108_HC.png\n",
      "Saved segmentation for 109_HC.png at output_segmentations/seg_109_HC.png\n",
      "Saved segmentation for 110_HC.png at output_segmentations/seg_110_HC.png\n",
      "Saved segmentation for 111_HC.png at output_segmentations/seg_111_HC.png\n",
      "Saved segmentation for 112_HC.png at output_segmentations/seg_112_HC.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved segmentation for 113_HC.png at output_segmentations/seg_113_HC.png\n",
      "Saved segmentation for 114_HC.png at output_segmentations/seg_114_HC.png\n",
      "Saved segmentation for 115_HC.png at output_segmentations/seg_115_HC.png\n",
      "Saved segmentation for 116_HC.png at output_segmentations/seg_116_HC.png\n",
      "Saved segmentation for 117_HC.png at output_segmentations/seg_117_HC.png\n",
      "Saved segmentation for 118_HC.png at output_segmentations/seg_118_HC.png\n",
      "Saved segmentation for 119_HC.png at output_segmentations/seg_119_HC.png\n",
      "Saved segmentation for 120_HC.png at output_segmentations/seg_120_HC.png\n",
      "Saved segmentation for 121_HC.png at output_segmentations/seg_121_HC.png\n",
      "Saved segmentation for 122_HC.png at output_segmentations/seg_122_HC.png\n",
      "Saved segmentation for 123_HC.png at output_segmentations/seg_123_HC.png\n",
      "Saved segmentation for 124_HC.png at output_segmentations/seg_124_HC.png\n",
      "Saved segmentation for 125_HC.png at output_segmentations/seg_125_HC.png\n",
      "Saved segmentation for 126_HC.png at output_segmentations/seg_126_HC.png\n",
      "Saved segmentation for 127_HC.png at output_segmentations/seg_127_HC.png\n",
      "Saved segmentation for 128_HC.png at output_segmentations/seg_128_HC.png\n",
      "Saved segmentation for 129_HC.png at output_segmentations/seg_129_HC.png\n",
      "Saved segmentation for 130_HC.png at output_segmentations/seg_130_HC.png\n",
      "Saved segmentation for 131_HC.png at output_segmentations/seg_131_HC.png\n",
      "Saved segmentation for 132_HC.png at output_segmentations/seg_132_HC.png\n",
      "Saved segmentation for 133_HC.png at output_segmentations/seg_133_HC.png\n",
      "Saved segmentation for 134_HC.png at output_segmentations/seg_134_HC.png\n",
      "Saved segmentation for 135_HC.png at output_segmentations/seg_135_HC.png\n",
      "Saved segmentation for 136_HC.png at output_segmentations/seg_136_HC.png\n",
      "Saved segmentation for 137_HC.png at output_segmentations/seg_137_HC.png\n",
      "Saved segmentation for 138_HC.png at output_segmentations/seg_138_HC.png\n",
      "Saved segmentation for 139_HC.png at output_segmentations/seg_139_HC.png\n",
      "Saved segmentation for 140_HC.png at output_segmentations/seg_140_HC.png\n",
      "Saved segmentation for 141_HC.png at output_segmentations/seg_141_HC.png\n",
      "Saved segmentation for 142_HC.png at output_segmentations/seg_142_HC.png\n",
      "Saved segmentation for 143_HC.png at output_segmentations/seg_143_HC.png\n",
      "Saved segmentation for 144_HC.png at output_segmentations/seg_144_HC.png\n",
      "Saved segmentation for 145_HC.png at output_segmentations/seg_145_HC.png\n",
      "Saved segmentation for 146_HC.png at output_segmentations/seg_146_HC.png\n",
      "Saved segmentation for 147_HC.png at output_segmentations/seg_147_HC.png\n",
      "Saved segmentation for 148_HC.png at output_segmentations/seg_148_HC.png\n",
      "Saved segmentation for 149_HC.png at output_segmentations/seg_149_HC.png\n",
      "Saved segmentation for 150_HC.png at output_segmentations/seg_150_HC.png\n",
      "Saved segmentation for 151_HC.png at output_segmentations/seg_151_HC.png\n",
      "Saved segmentation for 152_HC.png at output_segmentations/seg_152_HC.png\n",
      "Saved segmentation for 153_HC.png at output_segmentations/seg_153_HC.png\n",
      "Saved segmentation for 154_HC.png at output_segmentations/seg_154_HC.png\n",
      "Saved segmentation for 155_HC.png at output_segmentations/seg_155_HC.png\n",
      "Saved segmentation for 156_HC.png at output_segmentations/seg_156_HC.png\n",
      "Saved segmentation for 157_HC.png at output_segmentations/seg_157_HC.png\n",
      "Saved segmentation for 158_HC.png at output_segmentations/seg_158_HC.png\n",
      "Saved segmentation for 159_HC.png at output_segmentations/seg_159_HC.png\n",
      "Saved segmentation for 160_HC.png at output_segmentations/seg_160_HC.png\n",
      "Saved segmentation for 161_HC.png at output_segmentations/seg_161_HC.png\n",
      "Saved segmentation for 162_HC.png at output_segmentations/seg_162_HC.png\n",
      "Saved segmentation for 163_HC.png at output_segmentations/seg_163_HC.png\n",
      "Saved segmentation for 164_HC.png at output_segmentations/seg_164_HC.png\n",
      "Saved segmentation for 165_HC.png at output_segmentations/seg_165_HC.png\n",
      "Saved segmentation for 166_HC.png at output_segmentations/seg_166_HC.png\n",
      "Saved segmentation for 167_HC.png at output_segmentations/seg_167_HC.png\n",
      "Saved segmentation for 168_HC.png at output_segmentations/seg_168_HC.png\n",
      "Saved segmentation for 169_HC.png at output_segmentations/seg_169_HC.png\n",
      "Saved segmentation for 170_HC.png at output_segmentations/seg_170_HC.png\n",
      "Saved segmentation for 171_HC.png at output_segmentations/seg_171_HC.png\n",
      "Saved segmentation for 172_HC.png at output_segmentations/seg_172_HC.png\n",
      "Saved segmentation for 173_HC.png at output_segmentations/seg_173_HC.png\n",
      "Saved segmentation for 174_HC.png at output_segmentations/seg_174_HC.png\n",
      "Saved segmentation for 175_HC.png at output_segmentations/seg_175_HC.png\n",
      "Saved segmentation for 176_HC.png at output_segmentations/seg_176_HC.png\n",
      "Saved segmentation for 177_HC.png at output_segmentations/seg_177_HC.png\n",
      "Saved segmentation for 178_HC.png at output_segmentations/seg_178_HC.png\n",
      "Saved segmentation for 179_HC.png at output_segmentations/seg_179_HC.png\n",
      "Saved segmentation for 180_HC.png at output_segmentations/seg_180_HC.png\n",
      "Saved segmentation for 181_HC.png at output_segmentations/seg_181_HC.png\n",
      "Saved segmentation for 182_HC.png at output_segmentations/seg_182_HC.png\n",
      "Saved segmentation for 183_HC.png at output_segmentations/seg_183_HC.png\n",
      "Saved segmentation for 184_HC.png at output_segmentations/seg_184_HC.png\n",
      "Saved segmentation for 185_HC.png at output_segmentations/seg_185_HC.png\n",
      "Saved segmentation for 186_HC.png at output_segmentations/seg_186_HC.png\n",
      "Saved segmentation for 187_HC.png at output_segmentations/seg_187_HC.png\n",
      "Saved segmentation for 188_HC.png at output_segmentations/seg_188_HC.png\n",
      "Saved segmentation for 189_HC.png at output_segmentations/seg_189_HC.png\n",
      "Saved segmentation for 190_HC.png at output_segmentations/seg_190_HC.png\n",
      "Saved segmentation for 191_HC.png at output_segmentations/seg_191_HC.png\n",
      "Saved segmentation for 192_HC.png at output_segmentations/seg_192_HC.png\n",
      "Saved segmentation for 193_HC.png at output_segmentations/seg_193_HC.png\n",
      "Saved segmentation for 194_HC.png at output_segmentations/seg_194_HC.png\n",
      "Saved segmentation for 195_HC.png at output_segmentations/seg_195_HC.png\n",
      "Saved segmentation for 196_HC.png at output_segmentations/seg_196_HC.png\n",
      "Saved segmentation for 197_HC.png at output_segmentations/seg_197_HC.png\n",
      "Saved segmentation for 198_HC.png at output_segmentations/seg_198_HC.png\n",
      "Saved segmentation for 199_HC.png at output_segmentations/seg_199_HC.png\n",
      "Saved segmentation for 200_HC.png at output_segmentations/seg_200_HC.png\n",
      "Saved segmentation for 201_HC.png at output_segmentations/seg_201_HC.png\n",
      "Saved segmentation for 202_HC.png at output_segmentations/seg_202_HC.png\n",
      "Saved segmentation for 203_HC.png at output_segmentations/seg_203_HC.png\n",
      "Saved segmentation for 204_HC.png at output_segmentations/seg_204_HC.png\n",
      "Saved segmentation for 205_HC.png at output_segmentations/seg_205_HC.png\n",
      "Saved segmentation for 206_HC.png at output_segmentations/seg_206_HC.png\n",
      "Saved segmentation for 207_HC.png at output_segmentations/seg_207_HC.png\n",
      "Saved segmentation for 208_HC.png at output_segmentations/seg_208_HC.png\n",
      "Saved segmentation for 209_HC.png at output_segmentations/seg_209_HC.png\n",
      "Saved segmentation for 210_HC.png at output_segmentations/seg_210_HC.png\n",
      "Saved segmentation for 211_HC.png at output_segmentations/seg_211_HC.png\n",
      "Saved segmentation for 212_HC.png at output_segmentations/seg_212_HC.png\n",
      "Saved segmentation for 213_HC.png at output_segmentations/seg_213_HC.png\n",
      "Saved segmentation for 214_HC.png at output_segmentations/seg_214_HC.png\n",
      "Saved segmentation for 215_HC.png at output_segmentations/seg_215_HC.png\n",
      "Saved segmentation for 216_HC.png at output_segmentations/seg_216_HC.png\n",
      "Saved segmentation for 217_HC.png at output_segmentations/seg_217_HC.png\n",
      "Saved segmentation for 218_HC.png at output_segmentations/seg_218_HC.png\n",
      "Saved segmentation for 219_HC.png at output_segmentations/seg_219_HC.png\n",
      "Saved segmentation for 220_HC.png at output_segmentations/seg_220_HC.png\n",
      "Saved segmentation for 221_HC.png at output_segmentations/seg_221_HC.png\n",
      "Saved segmentation for 222_HC.png at output_segmentations/seg_222_HC.png\n",
      "Saved segmentation for 223_HC.png at output_segmentations/seg_223_HC.png\n",
      "Saved segmentation for 224_HC.png at output_segmentations/seg_224_HC.png\n",
      "Saved segmentation for 225_HC.png at output_segmentations/seg_225_HC.png\n",
      "Saved segmentation for 226_HC.png at output_segmentations/seg_226_HC.png\n",
      "Saved segmentation for 227_HC.png at output_segmentations/seg_227_HC.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved segmentation for 228_HC.png at output_segmentations/seg_228_HC.png\n",
      "Saved segmentation for 229_HC.png at output_segmentations/seg_229_HC.png\n",
      "Saved segmentation for 230_HC.png at output_segmentations/seg_230_HC.png\n",
      "Saved segmentation for 231_HC.png at output_segmentations/seg_231_HC.png\n",
      "Saved segmentation for 232_HC.png at output_segmentations/seg_232_HC.png\n",
      "Saved segmentation for 233_HC.png at output_segmentations/seg_233_HC.png\n",
      "Saved segmentation for 234_HC.png at output_segmentations/seg_234_HC.png\n",
      "Saved segmentation for 235_HC.png at output_segmentations/seg_235_HC.png\n",
      "Saved segmentation for 236_HC.png at output_segmentations/seg_236_HC.png\n",
      "Saved segmentation for 237_HC.png at output_segmentations/seg_237_HC.png\n",
      "Saved segmentation for 238_HC.png at output_segmentations/seg_238_HC.png\n",
      "Saved segmentation for 239_HC.png at output_segmentations/seg_239_HC.png\n",
      "Saved segmentation for 240_HC.png at output_segmentations/seg_240_HC.png\n",
      "Saved segmentation for 241_HC.png at output_segmentations/seg_241_HC.png\n",
      "Saved segmentation for 242_HC.png at output_segmentations/seg_242_HC.png\n",
      "Saved segmentation for 243_HC.png at output_segmentations/seg_243_HC.png\n",
      "Saved segmentation for 244_HC.png at output_segmentations/seg_244_HC.png\n",
      "Saved segmentation for 245_HC.png at output_segmentations/seg_245_HC.png\n",
      "Saved segmentation for 246_HC.png at output_segmentations/seg_246_HC.png\n",
      "Saved segmentation for 247_HC.png at output_segmentations/seg_247_HC.png\n",
      "Saved segmentation for 248_HC.png at output_segmentations/seg_248_HC.png\n",
      "Saved segmentation for 249_HC.png at output_segmentations/seg_249_HC.png\n",
      "Saved segmentation for 250_HC.png at output_segmentations/seg_250_HC.png\n",
      "Saved segmentation for 251_HC.png at output_segmentations/seg_251_HC.png\n",
      "Saved segmentation for 252_HC.png at output_segmentations/seg_252_HC.png\n",
      "Saved segmentation for 253_HC.png at output_segmentations/seg_253_HC.png\n",
      "Saved segmentation for 254_HC.png at output_segmentations/seg_254_HC.png\n",
      "Saved segmentation for 255_HC.png at output_segmentations/seg_255_HC.png\n",
      "Saved segmentation for 256_HC.png at output_segmentations/seg_256_HC.png\n",
      "Saved segmentation for 257_HC.png at output_segmentations/seg_257_HC.png\n",
      "Saved segmentation for 258_HC.png at output_segmentations/seg_258_HC.png\n",
      "Saved segmentation for 259_HC.png at output_segmentations/seg_259_HC.png\n",
      "Saved segmentation for 260_HC.png at output_segmentations/seg_260_HC.png\n",
      "Saved segmentation for 261_HC.png at output_segmentations/seg_261_HC.png\n",
      "Saved segmentation for 262_HC.png at output_segmentations/seg_262_HC.png\n",
      "Saved segmentation for 263_HC.png at output_segmentations/seg_263_HC.png\n",
      "Saved segmentation for 264_HC.png at output_segmentations/seg_264_HC.png\n",
      "Saved segmentation for 265_HC.png at output_segmentations/seg_265_HC.png\n",
      "Saved segmentation for 266_HC.png at output_segmentations/seg_266_HC.png\n",
      "Saved segmentation for 267_HC.png at output_segmentations/seg_267_HC.png\n",
      "Saved segmentation for 268_HC.png at output_segmentations/seg_268_HC.png\n",
      "Saved segmentation for 269_HC.png at output_segmentations/seg_269_HC.png\n",
      "Saved segmentation for 270_HC.png at output_segmentations/seg_270_HC.png\n",
      "Saved segmentation for 271_HC.png at output_segmentations/seg_271_HC.png\n",
      "Saved segmentation for 272_HC.png at output_segmentations/seg_272_HC.png\n",
      "Saved segmentation for 273_HC.png at output_segmentations/seg_273_HC.png\n",
      "Saved segmentation for 274_HC.png at output_segmentations/seg_274_HC.png\n",
      "Saved segmentation for 275_HC.png at output_segmentations/seg_275_HC.png\n",
      "Saved segmentation for 276_HC.png at output_segmentations/seg_276_HC.png\n",
      "Saved segmentation for 277_HC.png at output_segmentations/seg_277_HC.png\n",
      "Saved segmentation for 278_HC.png at output_segmentations/seg_278_HC.png\n",
      "Saved segmentation for 279_HC.png at output_segmentations/seg_279_HC.png\n",
      "Saved segmentation for 280_HC.png at output_segmentations/seg_280_HC.png\n",
      "Saved segmentation for 281_HC.png at output_segmentations/seg_281_HC.png\n",
      "Saved segmentation for 282_HC.png at output_segmentations/seg_282_HC.png\n",
      "Saved segmentation for 283_HC.png at output_segmentations/seg_283_HC.png\n",
      "Saved segmentation for 284_HC.png at output_segmentations/seg_284_HC.png\n",
      "Saved segmentation for 285_HC.png at output_segmentations/seg_285_HC.png\n",
      "Saved segmentation for 286_HC.png at output_segmentations/seg_286_HC.png\n",
      "Saved segmentation for 287_HC.png at output_segmentations/seg_287_HC.png\n",
      "Saved segmentation for 288_HC.png at output_segmentations/seg_288_HC.png\n",
      "Saved segmentation for 289_HC.png at output_segmentations/seg_289_HC.png\n",
      "Saved segmentation for 290_HC.png at output_segmentations/seg_290_HC.png\n",
      "Saved segmentation for 291_HC.png at output_segmentations/seg_291_HC.png\n",
      "Saved segmentation for 292_HC.png at output_segmentations/seg_292_HC.png\n",
      "Saved segmentation for 293_HC.png at output_segmentations/seg_293_HC.png\n",
      "Saved segmentation for 294_HC.png at output_segmentations/seg_294_HC.png\n",
      "Saved segmentation for 295_HC.png at output_segmentations/seg_295_HC.png\n",
      "Saved segmentation for 296_HC.png at output_segmentations/seg_296_HC.png\n",
      "Saved segmentation for 297_HC.png at output_segmentations/seg_297_HC.png\n",
      "Saved segmentation for 298_HC.png at output_segmentations/seg_298_HC.png\n",
      "Saved segmentation for 299_HC.png at output_segmentations/seg_299_HC.png\n",
      "Saved segmentation for 300_HC.png at output_segmentations/seg_300_HC.png\n",
      "Saved segmentation for 301_HC.png at output_segmentations/seg_301_HC.png\n",
      "Saved segmentation for 302_HC.png at output_segmentations/seg_302_HC.png\n",
      "Saved segmentation for 303_HC.png at output_segmentations/seg_303_HC.png\n",
      "Saved segmentation for 304_HC.png at output_segmentations/seg_304_HC.png\n",
      "Saved segmentation for 305_HC.png at output_segmentations/seg_305_HC.png\n",
      "Saved segmentation for 306_HC.png at output_segmentations/seg_306_HC.png\n",
      "Saved segmentation for 307_HC.png at output_segmentations/seg_307_HC.png\n",
      "Saved segmentation for 308_HC.png at output_segmentations/seg_308_HC.png\n",
      "Saved segmentation for 309_HC.png at output_segmentations/seg_309_HC.png\n",
      "Saved segmentation for 310_HC.png at output_segmentations/seg_310_HC.png\n",
      "Saved segmentation for 311_HC.png at output_segmentations/seg_311_HC.png\n",
      "Saved segmentation for 312_HC.png at output_segmentations/seg_312_HC.png\n",
      "Saved segmentation for 313_HC.png at output_segmentations/seg_313_HC.png\n",
      "Saved segmentation for 314_HC.png at output_segmentations/seg_314_HC.png\n",
      "Saved segmentation for 315_HC.png at output_segmentations/seg_315_HC.png\n",
      "Saved segmentation for 316_HC.png at output_segmentations/seg_316_HC.png\n",
      "Saved segmentation for 317_HC.png at output_segmentations/seg_317_HC.png\n",
      "Saved segmentation for 318_HC.png at output_segmentations/seg_318_HC.png\n",
      "Saved segmentation for 319_HC.png at output_segmentations/seg_319_HC.png\n",
      "Saved segmentation for 320_HC.png at output_segmentations/seg_320_HC.png\n",
      "Saved segmentation for 321_HC.png at output_segmentations/seg_321_HC.png\n",
      "Saved segmentation for 322_HC.png at output_segmentations/seg_322_HC.png\n",
      "Saved segmentation for 323_HC.png at output_segmentations/seg_323_HC.png\n",
      "Saved segmentation for 324_HC.png at output_segmentations/seg_324_HC.png\n",
      "Saved segmentation for 325_HC.png at output_segmentations/seg_325_HC.png\n",
      "Saved segmentation for 326_HC.png at output_segmentations/seg_326_HC.png\n",
      "Saved segmentation for 327_HC.png at output_segmentations/seg_327_HC.png\n",
      "Saved segmentation for 328_HC.png at output_segmentations/seg_328_HC.png\n",
      "Saved segmentation for 329_HC.png at output_segmentations/seg_329_HC.png\n",
      "Saved segmentation for 330_HC.png at output_segmentations/seg_330_HC.png\n",
      "Saved segmentation for 331_HC.png at output_segmentations/seg_331_HC.png\n",
      "Saved segmentation for 332_HC.png at output_segmentations/seg_332_HC.png\n",
      "Saved segmentation for 333_HC.png at output_segmentations/seg_333_HC.png\n",
      "Saved segmentation for 334_HC.png at output_segmentations/seg_334_HC.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define a test dataset class\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.images = sorted([os.path.join(image_dir, x) for x in os.listdir(image_dir) if x.endswith('.png')])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, image_path\n",
    "\n",
    "# Define deterministic transforms for test data\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((572, 572)),       # Resize to match model input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.pow(0.5))  # Gamma correction (same as training)\n",
    "])\n",
    "\n",
    "# Set the directory where your test images are stored\n",
    "test_dir = 'denoised_test_set'  # Adjust this to your actual test directory path\n",
    "\n",
    "# Create the test dataset and dataloader\n",
    "test_dataset = TestDataset(test_dir, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Instantiate your model (assumed defined in the notebook)\n",
    "model = UNetResNet101(n_classes=1).to(device)\n",
    "\n",
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load('unet_resnet101_model.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Create an output directory for the segmentation results\n",
    "output_dir = 'output_segmentations'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Inference loop: run the model on each test image and save the segmentation mask\n",
    "for image, image_path in test_loader:\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)  # Get the probability map from the model (sigmoid already applied)\n",
    "        # Threshold the probability map to obtain a binary segmentation mask\n",
    "        seg_mask = (output > 0.5).float()\n",
    "    \n",
    "    # Convert tensor to NumPy array and scale to 0-255 for visualization/saving\n",
    "    seg_mask_np = seg_mask.cpu().numpy().squeeze() * 255\n",
    "\n",
    "    # Generate output filename based on input image name\n",
    "    base_name = os.path.basename(image_path[0])\n",
    "    output_filename = os.path.join(output_dir, f\"seg_{base_name}\")\n",
    "    \n",
    "    # Save the segmentation mask image using OpenCV\n",
    "    cv2.imwrite(output_filename, seg_mask_np.astype('uint8'))\n",
    "    \n",
    "    # Optionally, display the segmentation mask using matplotlib\n",
    "#     plt.imshow(seg_mask_np, cmap='gray')\n",
    "#     plt.title(f\"Segmentation: {base_name}\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "    \n",
    "    print(f\"Saved segmentation for {base_name} at {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb148a",
   "metadata": {},
   "source": [
    "**Morphological Opening and Closing + Canny edge Detector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a94443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved edge image for: seg_306_HC.png\n",
      "Processed and saved edge image for: seg_301_HC.png\n",
      "Processed and saved edge image for: seg_189_HC.png\n",
      "Processed and saved edge image for: seg_274_HC.png\n",
      "Processed and saved edge image for: seg_033_HC.png\n",
      "Processed and saved edge image for: seg_195_HC.png\n",
      "Processed and saved edge image for: seg_147_HC.png\n",
      "Processed and saved edge image for: seg_224_HC.png\n",
      "Processed and saved edge image for: seg_296_HC.png\n",
      "Processed and saved edge image for: seg_204_HC.png\n",
      "Processed and saved edge image for: seg_318_HC.png\n",
      "Processed and saved edge image for: seg_270_HC.png\n",
      "Processed and saved edge image for: seg_010_HC.png\n",
      "Processed and saved edge image for: seg_262_HC.png\n",
      "Processed and saved edge image for: seg_117_HC.png\n",
      "Processed and saved edge image for: seg_008_HC.png\n",
      "Processed and saved edge image for: seg_278_HC.png\n",
      "Processed and saved edge image for: seg_094_HC.png\n",
      "Processed and saved edge image for: seg_186_HC.png\n",
      "Processed and saved edge image for: seg_135_HC.png\n",
      "Processed and saved edge image for: seg_303_HC.png\n",
      "Processed and saved edge image for: seg_244_HC.png\n",
      "Processed and saved edge image for: seg_057_HC.png\n",
      "Processed and saved edge image for: seg_060_HC.png\n",
      "Processed and saved edge image for: seg_115_HC.png\n",
      "Processed and saved edge image for: seg_314_HC.png\n",
      "Processed and saved edge image for: seg_247_HC.png\n",
      "Processed and saved edge image for: seg_188_HC.png\n",
      "Processed and saved edge image for: seg_037_HC.png\n",
      "Processed and saved edge image for: seg_129_HC.png\n",
      "Processed and saved edge image for: seg_184_HC.png\n",
      "Processed and saved edge image for: seg_310_HC.png\n",
      "Processed and saved edge image for: seg_180_HC.png\n",
      "Processed and saved edge image for: seg_222_HC.png\n",
      "Processed and saved edge image for: seg_242_HC.png\n",
      "Processed and saved edge image for: seg_121_HC.png\n",
      "Processed and saved edge image for: seg_238_HC.png\n",
      "Processed and saved edge image for: seg_128_HC.png\n",
      "Processed and saved edge image for: seg_143_HC.png\n",
      "Processed and saved edge image for: seg_046_HC.png\n",
      "Processed and saved edge image for: seg_239_HC.png\n",
      "Processed and saved edge image for: seg_315_HC.png\n",
      "Processed and saved edge image for: seg_005_HC.png\n",
      "Processed and saved edge image for: seg_279_HC.png\n",
      "Processed and saved edge image for: seg_007_HC.png\n",
      "Processed and saved edge image for: seg_297_HC.png\n",
      "Processed and saved edge image for: seg_040_HC.png\n",
      "Processed and saved edge image for: seg_036_HC.png\n",
      "Processed and saved edge image for: seg_182_HC.png\n",
      "Processed and saved edge image for: seg_089_HC.png\n",
      "Processed and saved edge image for: seg_110_HC.png\n",
      "Processed and saved edge image for: seg_176_HC.png\n",
      "Processed and saved edge image for: seg_027_HC.png\n",
      "Processed and saved edge image for: seg_165_HC.png\n",
      "Processed and saved edge image for: seg_015_HC.png\n",
      "Processed and saved edge image for: seg_221_HC.png\n",
      "Processed and saved edge image for: seg_305_HC.png\n",
      "Processed and saved edge image for: seg_229_HC.png\n",
      "Processed and saved edge image for: seg_174_HC.png\n",
      "Processed and saved edge image for: seg_079_HC.png\n",
      "Processed and saved edge image for: seg_058_HC.png\n",
      "Processed and saved edge image for: seg_201_HC.png\n",
      "Processed and saved edge image for: seg_134_HC.png\n",
      "Processed and saved edge image for: seg_001_HC.png\n",
      "Processed and saved edge image for: seg_044_HC.png\n",
      "Processed and saved edge image for: seg_323_HC.png\n",
      "Processed and saved edge image for: seg_285_HC.png\n",
      "Processed and saved edge image for: seg_282_HC.png\n",
      "Processed and saved edge image for: seg_281_HC.png\n",
      "Processed and saved edge image for: seg_230_HC.png\n",
      "Processed and saved edge image for: seg_298_HC.png\n",
      "Processed and saved edge image for: seg_250_HC.png\n",
      "Processed and saved edge image for: seg_322_HC.png\n",
      "Processed and saved edge image for: seg_325_HC.png\n",
      "Processed and saved edge image for: seg_292_HC.png\n",
      "Processed and saved edge image for: seg_068_HC.png\n",
      "Processed and saved edge image for: seg_139_HC.png\n",
      "Processed and saved edge image for: seg_127_HC.png\n",
      "Processed and saved edge image for: seg_022_HC.png\n",
      "Processed and saved edge image for: seg_111_HC.png\n",
      "Processed and saved edge image for: seg_288_HC.png\n",
      "Processed and saved edge image for: seg_000_HC.png\n",
      "Processed and saved edge image for: seg_198_HC.png\n",
      "Processed and saved edge image for: seg_160_HC.png\n",
      "Processed and saved edge image for: seg_051_HC.png\n",
      "Processed and saved edge image for: seg_231_HC.png\n",
      "Processed and saved edge image for: seg_327_HC.png\n",
      "Processed and saved edge image for: seg_039_HC.png\n",
      "Processed and saved edge image for: seg_082_HC.png\n",
      "Processed and saved edge image for: seg_161_HC.png\n",
      "Processed and saved edge image for: seg_034_HC.png\n",
      "Processed and saved edge image for: seg_256_HC.png\n",
      "Processed and saved edge image for: seg_102_HC.png\n",
      "Processed and saved edge image for: seg_317_HC.png\n",
      "Processed and saved edge image for: seg_299_HC.png\n",
      "Processed and saved edge image for: seg_112_HC.png\n",
      "Processed and saved edge image for: seg_218_HC.png\n",
      "Processed and saved edge image for: seg_237_HC.png\n",
      "Processed and saved edge image for: seg_226_HC.png\n",
      "Processed and saved edge image for: seg_016_HC.png\n",
      "Processed and saved edge image for: seg_163_HC.png\n",
      "Processed and saved edge image for: seg_023_HC.png\n",
      "Processed and saved edge image for: seg_240_HC.png\n",
      "Processed and saved edge image for: seg_178_HC.png\n",
      "Processed and saved edge image for: seg_088_HC.png\n",
      "Processed and saved edge image for: seg_210_HC.png\n",
      "Processed and saved edge image for: seg_120_HC.png\n",
      "Processed and saved edge image for: seg_277_HC.png\n",
      "Processed and saved edge image for: seg_269_HC.png\n",
      "Processed and saved edge image for: seg_167_HC.png\n",
      "Processed and saved edge image for: seg_151_HC.png\n",
      "Processed and saved edge image for: seg_267_HC.png\n",
      "Processed and saved edge image for: seg_045_HC.png\n",
      "Processed and saved edge image for: seg_141_HC.png\n",
      "Processed and saved edge image for: seg_013_HC.png\n",
      "Processed and saved edge image for: seg_123_HC.png\n",
      "Processed and saved edge image for: seg_233_HC.png\n",
      "Processed and saved edge image for: seg_096_HC.png\n",
      "Processed and saved edge image for: seg_028_HC.png\n",
      "Processed and saved edge image for: seg_168_HC.png\n",
      "Processed and saved edge image for: seg_183_HC.png\n",
      "Processed and saved edge image for: seg_002_HC.png\n",
      "Processed and saved edge image for: seg_253_HC.png\n",
      "Processed and saved edge image for: seg_241_HC.png\n",
      "Processed and saved edge image for: seg_284_HC.png\n",
      "Processed and saved edge image for: seg_157_HC.png\n",
      "Processed and saved edge image for: seg_312_HC.png\n",
      "Processed and saved edge image for: seg_050_HC.png\n",
      "Processed and saved edge image for: seg_316_HC.png\n",
      "Processed and saved edge image for: seg_144_HC.png\n",
      "Processed and saved edge image for: seg_332_HC.png\n",
      "Processed and saved edge image for: seg_319_HC.png\n",
      "Processed and saved edge image for: seg_206_HC.png\n",
      "Processed and saved edge image for: seg_074_HC.png\n",
      "Processed and saved edge image for: seg_116_HC.png\n",
      "Processed and saved edge image for: seg_019_HC.png\n",
      "Processed and saved edge image for: seg_158_HC.png\n",
      "Processed and saved edge image for: seg_246_HC.png\n",
      "Processed and saved edge image for: seg_276_HC.png\n",
      "Processed and saved edge image for: seg_311_HC.png\n",
      "Processed and saved edge image for: seg_091_HC.png\n",
      "Processed and saved edge image for: seg_066_HC.png\n",
      "Processed and saved edge image for: seg_062_HC.png\n",
      "Processed and saved edge image for: seg_035_HC.png\n",
      "Processed and saved edge image for: seg_199_HC.png\n",
      "Processed and saved edge image for: seg_187_HC.png\n",
      "Processed and saved edge image for: seg_243_HC.png\n",
      "Processed and saved edge image for: seg_215_HC.png\n",
      "Processed and saved edge image for: seg_025_HC.png\n",
      "Processed and saved edge image for: seg_258_HC.png\n",
      "Processed and saved edge image for: seg_287_HC.png\n",
      "Processed and saved edge image for: seg_012_HC.png\n",
      "Processed and saved edge image for: seg_107_HC.png\n",
      "Processed and saved edge image for: seg_093_HC.png\n",
      "Processed and saved edge image for: seg_011_HC.png\n",
      "Processed and saved edge image for: seg_197_HC.png\n",
      "Processed and saved edge image for: seg_077_HC.png\n",
      "Processed and saved edge image for: seg_009_HC.png\n",
      "Processed and saved edge image for: seg_205_HC.png\n",
      "Processed and saved edge image for: seg_059_HC.png\n",
      "Processed and saved edge image for: seg_104_HC.png\n",
      "Processed and saved edge image for: seg_099_HC.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved edge image for: seg_252_HC.png\n",
      "Processed and saved edge image for: seg_124_HC.png\n",
      "Processed and saved edge image for: seg_131_HC.png\n",
      "Processed and saved edge image for: seg_055_HC.png\n",
      "Processed and saved edge image for: seg_300_HC.png\n",
      "Processed and saved edge image for: seg_328_HC.png\n",
      "Processed and saved edge image for: seg_223_HC.png\n",
      "Processed and saved edge image for: seg_295_HC.png\n",
      "Processed and saved edge image for: seg_259_HC.png\n",
      "Processed and saved edge image for: seg_265_HC.png\n",
      "Processed and saved edge image for: seg_092_HC.png\n",
      "Processed and saved edge image for: seg_208_HC.png\n",
      "Processed and saved edge image for: seg_181_HC.png\n",
      "Processed and saved edge image for: seg_179_HC.png\n",
      "Processed and saved edge image for: seg_331_HC.png\n",
      "Processed and saved edge image for: seg_273_HC.png\n",
      "Processed and saved edge image for: seg_080_HC.png\n",
      "Processed and saved edge image for: seg_193_HC.png\n",
      "Processed and saved edge image for: seg_018_HC.png\n",
      "Processed and saved edge image for: seg_191_HC.png\n",
      "Processed and saved edge image for: seg_154_HC.png\n",
      "Processed and saved edge image for: seg_309_HC.png\n",
      "Processed and saved edge image for: seg_330_HC.png\n",
      "Processed and saved edge image for: seg_083_HC.png\n",
      "Processed and saved edge image for: seg_133_HC.png\n",
      "Processed and saved edge image for: seg_185_HC.png\n",
      "Processed and saved edge image for: seg_065_HC.png\n",
      "Processed and saved edge image for: seg_251_HC.png\n",
      "Processed and saved edge image for: seg_324_HC.png\n",
      "Processed and saved edge image for: seg_020_HC.png\n",
      "Processed and saved edge image for: seg_192_HC.png\n",
      "Processed and saved edge image for: seg_126_HC.png\n",
      "Processed and saved edge image for: seg_203_HC.png\n",
      "Processed and saved edge image for: seg_032_HC.png\n",
      "Processed and saved edge image for: seg_261_HC.png\n",
      "Processed and saved edge image for: seg_073_HC.png\n",
      "Processed and saved edge image for: seg_031_HC.png\n",
      "Processed and saved edge image for: seg_171_HC.png\n",
      "Processed and saved edge image for: seg_014_HC.png\n",
      "Processed and saved edge image for: seg_264_HC.png\n",
      "Processed and saved edge image for: seg_249_HC.png\n",
      "Processed and saved edge image for: seg_052_HC.png\n",
      "Processed and saved edge image for: seg_069_HC.png\n",
      "Processed and saved edge image for: seg_098_HC.png\n",
      "Processed and saved edge image for: seg_307_HC.png\n",
      "Processed and saved edge image for: seg_122_HC.png\n",
      "Processed and saved edge image for: seg_257_HC.png\n",
      "Processed and saved edge image for: seg_064_HC.png\n",
      "Processed and saved edge image for: seg_232_HC.png\n",
      "Processed and saved edge image for: seg_248_HC.png\n",
      "Processed and saved edge image for: seg_290_HC.png\n",
      "Processed and saved edge image for: seg_095_HC.png\n",
      "Processed and saved edge image for: seg_100_HC.png\n",
      "Processed and saved edge image for: seg_291_HC.png\n",
      "Processed and saved edge image for: seg_026_HC.png\n",
      "Processed and saved edge image for: seg_225_HC.png\n",
      "Processed and saved edge image for: seg_320_HC.png\n",
      "Processed and saved edge image for: seg_149_HC.png\n",
      "Processed and saved edge image for: seg_155_HC.png\n",
      "Processed and saved edge image for: seg_087_HC.png\n",
      "Processed and saved edge image for: seg_289_HC.png\n",
      "Processed and saved edge image for: seg_119_HC.png\n",
      "Processed and saved edge image for: seg_153_HC.png\n",
      "Processed and saved edge image for: seg_140_HC.png\n",
      "Processed and saved edge image for: seg_097_HC.png\n",
      "Processed and saved edge image for: seg_211_HC.png\n",
      "Processed and saved edge image for: seg_105_HC.png\n",
      "Processed and saved edge image for: seg_209_HC.png\n",
      "Processed and saved edge image for: seg_067_HC.png\n",
      "Processed and saved edge image for: seg_130_HC.png\n",
      "Processed and saved edge image for: seg_101_HC.png\n",
      "Processed and saved edge image for: seg_313_HC.png\n",
      "Processed and saved edge image for: seg_326_HC.png\n",
      "Processed and saved edge image for: seg_268_HC.png\n",
      "Processed and saved edge image for: seg_043_HC.png\n",
      "Processed and saved edge image for: seg_177_HC.png\n",
      "Processed and saved edge image for: seg_219_HC.png\n",
      "Processed and saved edge image for: seg_333_HC.png\n",
      "Processed and saved edge image for: seg_029_HC.png\n",
      "Processed and saved edge image for: seg_196_HC.png\n",
      "Processed and saved edge image for: seg_190_HC.png\n",
      "Processed and saved edge image for: seg_072_HC.png\n",
      "Processed and saved edge image for: seg_125_HC.png\n",
      "Processed and saved edge image for: seg_090_HC.png\n",
      "Processed and saved edge image for: seg_081_HC.png\n",
      "Processed and saved edge image for: seg_159_HC.png\n",
      "Processed and saved edge image for: seg_114_HC.png\n",
      "Processed and saved edge image for: seg_053_HC.png\n",
      "Processed and saved edge image for: seg_321_HC.png\n",
      "Processed and saved edge image for: seg_228_HC.png\n",
      "Processed and saved edge image for: seg_056_HC.png\n",
      "Processed and saved edge image for: seg_061_HC.png\n",
      "Processed and saved edge image for: seg_146_HC.png\n",
      "Processed and saved edge image for: seg_004_HC.png\n",
      "Processed and saved edge image for: seg_078_HC.png\n",
      "Processed and saved edge image for: seg_145_HC.png\n",
      "Processed and saved edge image for: seg_152_HC.png\n",
      "Processed and saved edge image for: seg_236_HC.png\n",
      "Processed and saved edge image for: seg_293_HC.png\n",
      "Processed and saved edge image for: seg_109_HC.png\n",
      "Processed and saved edge image for: seg_283_HC.png\n",
      "Processed and saved edge image for: seg_334_HC.png\n",
      "Processed and saved edge image for: seg_255_HC.png\n",
      "Processed and saved edge image for: seg_194_HC.png\n",
      "Processed and saved edge image for: seg_156_HC.png\n",
      "Processed and saved edge image for: seg_260_HC.png\n",
      "Processed and saved edge image for: seg_076_HC.png\n",
      "Processed and saved edge image for: seg_217_HC.png\n",
      "Processed and saved edge image for: seg_263_HC.png\n",
      "Processed and saved edge image for: seg_136_HC.png\n",
      "Processed and saved edge image for: seg_106_HC.png\n",
      "Processed and saved edge image for: seg_150_HC.png\n",
      "Processed and saved edge image for: seg_164_HC.png\n",
      "Processed and saved edge image for: seg_070_HC.png\n",
      "Processed and saved edge image for: seg_030_HC.png\n",
      "Processed and saved edge image for: seg_132_HC.png\n",
      "Processed and saved edge image for: seg_275_HC.png\n",
      "Processed and saved edge image for: seg_272_HC.png\n",
      "Processed and saved edge image for: seg_235_HC.png\n",
      "Processed and saved edge image for: seg_175_HC.png\n",
      "Processed and saved edge image for: seg_148_HC.png\n",
      "Processed and saved edge image for: seg_212_HC.png\n",
      "Processed and saved edge image for: seg_108_HC.png\n",
      "Processed and saved edge image for: seg_071_HC.png\n",
      "Processed and saved edge image for: seg_304_HC.png\n",
      "Processed and saved edge image for: seg_075_HC.png\n",
      "Processed and saved edge image for: seg_271_HC.png\n",
      "Processed and saved edge image for: seg_294_HC.png\n",
      "Processed and saved edge image for: seg_254_HC.png\n",
      "Processed and saved edge image for: seg_202_HC.png\n",
      "Processed and saved edge image for: seg_302_HC.png\n",
      "Processed and saved edge image for: seg_169_HC.png\n",
      "Processed and saved edge image for: seg_086_HC.png\n",
      "Processed and saved edge image for: seg_084_HC.png\n",
      "Processed and saved edge image for: seg_166_HC.png\n",
      "Processed and saved edge image for: seg_003_HC.png\n",
      "Processed and saved edge image for: seg_113_HC.png\n",
      "Processed and saved edge image for: seg_170_HC.png\n",
      "Processed and saved edge image for: seg_162_HC.png\n",
      "Processed and saved edge image for: seg_042_HC.png\n",
      "Processed and saved edge image for: seg_216_HC.png\n",
      "Processed and saved edge image for: seg_280_HC.png\n",
      "Processed and saved edge image for: seg_220_HC.png\n",
      "Processed and saved edge image for: seg_286_HC.png\n",
      "Processed and saved edge image for: seg_048_HC.png\n",
      "Processed and saved edge image for: seg_024_HC.png\n",
      "Processed and saved edge image for: seg_085_HC.png\n",
      "Processed and saved edge image for: seg_063_HC.png\n",
      "Processed and saved edge image for: seg_172_HC.png\n",
      "Processed and saved edge image for: seg_047_HC.png\n",
      "Processed and saved edge image for: seg_103_HC.png\n",
      "Processed and saved edge image for: seg_266_HC.png\n",
      "Processed and saved edge image for: seg_200_HC.png\n",
      "Processed and saved edge image for: seg_006_HC.png\n",
      "Processed and saved edge image for: seg_137_HC.png\n",
      "Processed and saved edge image for: seg_308_HC.png\n",
      "Processed and saved edge image for: seg_054_HC.png\n",
      "Processed and saved edge image for: seg_173_HC.png\n",
      "Processed and saved edge image for: seg_227_HC.png\n",
      "Processed and saved edge image for: seg_213_HC.png\n",
      "Processed and saved edge image for: seg_038_HC.png\n",
      "Processed and saved edge image for: seg_214_HC.png\n",
      "Processed and saved edge image for: seg_021_HC.png\n",
      "Processed and saved edge image for: seg_118_HC.png\n",
      "Processed and saved edge image for: seg_041_HC.png\n",
      "Processed and saved edge image for: seg_329_HC.png\n",
      "Processed and saved edge image for: seg_245_HC.png\n",
      "Processed and saved edge image for: seg_138_HC.png\n",
      "Processed and saved edge image for: seg_142_HC.png\n",
      "Processed and saved edge image for: seg_017_HC.png\n",
      "Processed and saved edge image for: seg_207_HC.png\n",
      "Processed and saved edge image for: seg_234_HC.png\n",
      "Processed and saved edge image for: seg_049_HC.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define input and output folders\n",
    "input_folder = 'output_segmentations'\n",
    "output_folder = 'output_edges'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define a structuring element for the morphological operations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Loop over all segmented images in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.png'):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        # Read the segmentation image in grayscale\n",
    "        seg_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Apply morphological opening (erosion followed by dilation) to remove small artifacts\n",
    "        opened = cv2.morphologyEx(seg_img, cv2.MORPH_OPEN, kernel)\n",
    "        # Then apply morphological closing (dilation followed by erosion) to fill small holes\n",
    "        closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # Apply Canny edge detector to extract the contour\n",
    "        # Adjust thresholds as necessary (here, 50 and 150 are example values)\n",
    "        edges = cv2.Canny(closed, 50, 150)\n",
    "        \n",
    "        # Save the edge-detected image\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, edges)\n",
    "        \n",
    "        # Optionally, display the original segmentation, post-morphology, and edge image side by side\n",
    "#         plt.figure(figsize=(12, 4))\n",
    "#         plt.subplot(1, 3, 1)\n",
    "#         plt.imshow(seg_img, cmap='gray')\n",
    "#         plt.title('Original Segmentation')\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         plt.subplot(1, 3, 2)\n",
    "#         plt.imshow(closed, cmap='gray')\n",
    "#         plt.title('After Morphological Ops')\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         plt.subplot(1, 3, 3)\n",
    "#         plt.imshow(edges, cmap='gray')\n",
    "#         plt.title('Canny Edges')\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         plt.show()\n",
    "        print(f\"Processed and saved edge image for: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a792bc6",
   "metadata": {},
   "source": [
    "**Ellipse fiting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa48dc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'ellipse_results.csv' saved with 335 rows.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "# --- Step 1: Load the pixel size information from the CSV file ---\n",
    "# Assume your CSV file 'test_set_pixel_size.csv' has at least these columns:\n",
    "# filename,pixel_size_mm\n",
    "pixel_size_dict = {}\n",
    "with open('test_set_pixel_size.csv', mode='r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        # Adjust the column names if they are different in your CSV file.\n",
    "        filename_csv = row['filename']\n",
    "        pixel_size_mm = float(row['pixel size(mm)'])\n",
    "        pixel_size_dict[filename_csv] = pixel_size_mm\n",
    "\n",
    "# --- Step 2: Process the edge images and fit ellipses ---\n",
    "edges_folder = 'output_edges'\n",
    "csv_output = 'ellipse_results.csv'\n",
    "header = [\"filename\", \"center_x_mm\", \"center_y_mm\", \"semi_axes_a_mm\", \"semi_axes_b_mm\", \"angle_rad\"]\n",
    "rows = []\n",
    "\n",
    "for filename in sorted(os.listdir(edges_folder)):\n",
    "    if filename.endswith('.png'):\n",
    "        filepath = os.path.join(edges_folder, filename)\n",
    "        # Read the edge image in grayscale\n",
    "        edge_img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Find contours in the edge image\n",
    "        contours, _ = cv2.findContours(edge_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if len(contours) == 0:\n",
    "            print(f\"No contours found in {filename}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Choose the largest contour (assumed to be the head contour)\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # cv2.fitEllipse requires at least 5 points\n",
    "        if len(largest_contour) < 5:\n",
    "            print(f\"Not enough points for ellipse fitting in {filename}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Fit ellipse to the largest contour\n",
    "        ellipse = cv2.fitEllipse(largest_contour)\n",
    "        # ellipse returns ((center_x, center_y), (full_axis_length_a, full_axis_length_b), angle_in_degrees)\n",
    "        center, axes, angle = ellipse\n",
    "        # Compute semi-axes (the axes given are the full lengths)\n",
    "        semi_a = axes[0] / 2.0  # semi-major axis in pixels\n",
    "        semi_b = axes[1] / 2.0  # semi-minor axis in pixels\n",
    "\n",
    "        # --- Step 3: Look up the pixel conversion factor for this image ---\n",
    "        # The filenames in the CSV are expected to be like \"001_HC.png\"\n",
    "        # and our edge images are named \"seg_001_HC.png\". Remove the \"seg_\" prefix.\n",
    "        base_filename = filename.replace(\"seg_\", \"\", 1)\n",
    "        if base_filename in pixel_size_dict:\n",
    "            pixel_to_mm = pixel_size_dict[base_filename]\n",
    "        else:\n",
    "            print(f\"Pixel size for {base_filename} not found in CSV. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Convert measurements from pixels to millimeters\n",
    "        center_x_mm = center[0] * pixel_to_mm\n",
    "        center_y_mm = center[1] * pixel_to_mm\n",
    "        semi_a_mm = semi_a * pixel_to_mm\n",
    "        semi_b_mm = semi_b * pixel_to_mm\n",
    "        \n",
    "        # Convert angle from degrees to radians\n",
    "        angle_rad = math.radians(angle)\n",
    "        \n",
    "        # Append the result: filename, center_x_mm, center_y_mm, semi_axes_a_mm, semi_axes_b_mm, angle_rad\n",
    "        rows.append([base_filename, center_x_mm, center_y_mm, semi_a_mm, semi_b_mm, angle_rad])\n",
    "\n",
    "# --- Step 4: Write results to a CSV file ---\n",
    "with open(csv_output, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"CSV file '{csv_output}' saved with {len(rows)} rows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
